\section{Decision Function Aggregation}
Although I chose to pursue a random sampling approach, an alternative approach could involve aggregating voting functions in such a way that $n$ voting functions could be collectively queried significantly faster than they could be queried individually. These aggregation methods would involve exploiting the structure of the voting functions. Here, I briefly explore some separate aggregation strategies.
\subsection{Decision Boundaries}
If each different AV problem can be represented as a point in some Cartesian space, then a hyperplane in this space can be thought of as a voting function, where all the points on one side of the plane get a vote of one , and all the points on the other side get a vote of negative one. If the set of all voting functions contains only hyperplanes, we can exploit the geometric structure of this set to quickly query all decision functions. More specifically, we can compute the arrangement of these hyperplanes, where each cell in the arrangement contains the sum of all the ones (for all every plane below the cell that classifies these points as a one), and all the negative ones (for planes above the cell that classify it as a negative one). This combined sum gives us the relative voting difference for each point in every cell.

Assuming we have computed the arrangement of all the decision boundaries, use of the correct data structure should allow us to efficiently query any one point in this space. Unfortunately, computing the arrangement of hyperplanes in $\mathbb{R}^d$ has been shown to be $O(n^d)$ -- thus, any work on this approach will need to deal with this problem, presumably via a clever dimension reduction.
\subsection{Decision Trees}